{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from spacy.symbols import ORTH\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>text</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>58522792</td>\n",
       "      <td>16567081</td>\n",
       "      <td>b\"                                 FINAL REPOR...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>58213163</td>\n",
       "      <td>16567081</td>\n",
       "      <td>b'                                 FINAL REPOR...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>59835582</td>\n",
       "      <td>16043746</td>\n",
       "      <td>b'                                 FINAL REPOR...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>51487790</td>\n",
       "      <td>16456872</td>\n",
       "      <td>b'                                 FINAL REPOR...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>59750073</td>\n",
       "      <td>16824069</td>\n",
       "      <td>b'                                 FINAL REPOR...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id  subject_id                                               text  \\\n",
       "0  58522792    16567081  b\"                                 FINAL REPOR...   \n",
       "1  58213163    16567081  b'                                 FINAL REPOR...   \n",
       "2  59835582    16043746  b'                                 FINAL REPOR...   \n",
       "3  51487790    16456872  b'                                 FINAL REPOR...   \n",
       "4  59750073    16824069  b'                                 FINAL REPOR...   \n",
       "\n",
       "   Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "0          0.0           0.0            0.0    0.0   \n",
       "1          0.0           1.0            0.0    1.0   \n",
       "2          0.0           0.0            0.0    0.0   \n",
       "3          0.0           0.0            0.0    0.0   \n",
       "4          0.0           0.0            0.0    0.0   \n",
       "\n",
       "   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n",
       "0                         0.0       0.0          0.0           0.0   \n",
       "1                         0.0       0.0          0.0           0.0   \n",
       "2                         0.0       0.0          0.0           0.0   \n",
       "3                         0.0       0.0          0.0           0.0   \n",
       "4                         0.0       0.0          0.0           0.0   \n",
       "\n",
       "   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n",
       "0         0.0               0.0            0.0        1.0           0.0   \n",
       "1         0.0               1.0            0.0        0.0           0.0   \n",
       "2         1.0               0.0            0.0        0.0           0.0   \n",
       "3         1.0               0.0            0.0        0.0           0.0   \n",
       "4         1.0               0.0            0.0        0.0           0.0   \n",
       "\n",
       "   Support Devices  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mimic_data = pd.read_csv(\"data/text_binary.csv\")\n",
    "mimic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>text</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>58522792</td>\n",
       "      <td>16567081</td>\n",
       "      <td>b\"                                 final repor...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>58213163</td>\n",
       "      <td>16567081</td>\n",
       "      <td>b'                                 final repor...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>59835582</td>\n",
       "      <td>16043746</td>\n",
       "      <td>b'                                 final repor...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>51487790</td>\n",
       "      <td>16456872</td>\n",
       "      <td>b'                                 final repor...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>59750073</td>\n",
       "      <td>16824069</td>\n",
       "      <td>b'                                 final repor...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id  subject_id                                               text  \\\n",
       "0  58522792    16567081  b\"                                 final repor...   \n",
       "1  58213163    16567081  b'                                 final repor...   \n",
       "2  59835582    16043746  b'                                 final repor...   \n",
       "3  51487790    16456872  b'                                 final repor...   \n",
       "4  59750073    16824069  b'                                 final repor...   \n",
       "\n",
       "   Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "0          0.0           0.0            0.0    0.0   \n",
       "1          0.0           1.0            0.0    1.0   \n",
       "2          0.0           0.0            0.0    0.0   \n",
       "3          0.0           0.0            0.0    0.0   \n",
       "4          0.0           0.0            0.0    0.0   \n",
       "\n",
       "   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n",
       "0                         0.0       0.0          0.0           0.0   \n",
       "1                         0.0       0.0          0.0           0.0   \n",
       "2                         0.0       0.0          0.0           0.0   \n",
       "3                         0.0       0.0          0.0           0.0   \n",
       "4                         0.0       0.0          0.0           0.0   \n",
       "\n",
       "   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n",
       "0         0.0               0.0            0.0        1.0           0.0   \n",
       "1         0.0               1.0            0.0        0.0           0.0   \n",
       "2         1.0               0.0            0.0        0.0           0.0   \n",
       "3         1.0               0.0            0.0        0.0           0.0   \n",
       "4         1.0               0.0            0.0        0.0           0.0   \n",
       "\n",
       "   Support Devices  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_data = mimic_data.copy()\n",
    "binary_data.text = binary_data.text.str.lower()\n",
    "binary_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = binary_data[['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n",
    "                      'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding','Pleural Effusion', 'Pleural Other', \n",
    "                      'Pneumonia', 'Pneumothorax', 'Support Devices']]\n",
    "labels['labels'] = labels.values.tolist()\n",
    "y = labels[['labels']]\n",
    "X = binary_data[['text']]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning & Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all '\\\\n' from the text\n",
    "re_newlines = re.compile('\\\\\\\\n')\n",
    "def sub_newlines(x): return re_newlines.sub('',x)\n",
    "\n",
    "# remove all special characters from the text, keep only alphanumeric and spaces\n",
    "re_letters = re.compile('[^A-Za-z0-9 ]')\n",
    "def sub_letters(x): return re_letters.sub('', x)\n",
    "\n",
    "# remove excessive spacing otherwise you end up with \" \" substrings\n",
    "re_spaces = re.compile('\\s+')\n",
    "def sub_spaces(x): return re_spaces.sub(' ', x)\n",
    "                \n",
    "# tokenize all words.\n",
    "my_tok = spacy.load('en')\n",
    "def spacy_tok(x): \n",
    "    return [tok.text for tok in my_tok.tokenizer(sub_spaces\n",
    "                                                 (sub_letters\n",
    "                                                 (sub_newlines(x))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b final report type of examination chest pa and lateral indication yearold male patient with recent pneumonia diagnosed and treated at another facility xray not available now with continued cough and wheeze history of copd remaining evidence of pneumonia findings pa and lateral chest views were obtained with patient in upright position analysis is performed in direct comparison with the next preceding chest examination of the heart size remains normal no typical configurational abnormality is seen the thoracic aorta is moderately widened and somewhat elongated but no local contour abnormalities are identified the pulmonary vasculature is not congested there exists however some irregular peripheral vascular distribution most marked on the bases and coinciding with some slightly hypertranslucent pulmonary areas and flattened low positioned diaphragms are indicative of copd when direct comparison is made with the previous examination of there is a hazy mild degree of density in the left base shows a corresponding local thickening of the lower portion of the major fissure on the left side this finding is consistent with some resolving pneumonic process such as recent pneumonia in resolution skeletal changes which were characterized by some longitudinal calcification in the anterior ligaments of the thoracic spine appears stable and has not progressed no new skeletal abnormalities identified impression findings of general copd as before minor pleural and parenchymal hazy densities on the left base probably pneumonia in resolution and match the clinical report of a recent pneumonia if patients symptoms continue recommend another follow up examination in a week or so'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_spaces(sub_letters(sub_newlines(binary_data.text[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy_tok(binary_data.text[0])[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(text):\n",
    "    counts = Counter()\n",
    "    for word in text:\n",
    "        counts.update(spacy_tok(word)[1:])\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = get_counts(binary_data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37093"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in list(word_count):\n",
    "    if word_count[word] < 3:\n",
    "        del word_count[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15527"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = {\"<PAD>\":0, \"UNK\":1} # init with padding and unknown\n",
    "words = [\"<PAD>\", \"UNK\"]\n",
    "for word in word_count:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15529"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(text):\n",
    "    enc = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in text.split()])\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binary_Mimic(Dataset):\n",
    "    def __init__(self, X, y, vocab):\n",
    "        self.x = [encode_sentence(x) for x in X.text]\n",
    "        self.y = y.labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_train = Binary_Mimic(X_train, y_train, vocab2index)\n",
    "b_valid = Binary_Mimic(X_val, y_val, vocab2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"Creates mini-batch tensors from the list of tuples (sentences, labels).\n",
    "    \n",
    "    Need custom collate_fn because merging sequences (including padding) is not \n",
    "    supported in default. Sequences are padded to the maximum length of mini-batch \n",
    "    sequences (dynamic padding).\n",
    "    \n",
    "    Args:\n",
    "        data: list of tuple (sentence, label). \n",
    "            - list of word indices of variable length\n",
    "            - label, 0 or 1\n",
    "    Returns:\n",
    "        packed_batch: (PackedSequence), see torch.nn.utils.rnn.pack_padded_sequence\n",
    "        sencences: torch tensor of shape (batch_size, max_len).\n",
    "        labels: torch tensor of shape (batch_size, 1).\n",
    "        lengths: list; valid length for each padded sentence. \n",
    "    \"\"\"\n",
    "    # Sort a data list by sentences length (descending order).\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    sentences, labels = zip(*data)\n",
    "    \n",
    "    # stack labels\n",
    "    labels = torch.Tensor(labels)\n",
    "    \n",
    "    # Merge sentences\n",
    "    lengths = [len(s) for s in sentences]\n",
    "   \n",
    "    sents = torch.zeros(len(sentences), max(lengths)).long()\n",
    "    for i, s in enumerate(sentences):\n",
    "        end = lengths[i]\n",
    "        sents[i, :end] = torch.Tensor(s[:end])        \n",
    "    \n",
    "    return sents, lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    2,    1,    1,   30,    5,    1,  376,  565,    1,  641,    1,\n",
       "            1,    1,    1,    7,  194,  182,    1,    1,    1,    9,    1,    1,\n",
       "            1,    8,    9,   10,  194,    5,   46,    1,    1,    1,  354,   57,\n",
       "           42,  340, 1134,  500,  409,  410,   46,  102,    1,  128,    1,   97,\n",
       "          168,  452,  267,  404,  268,  399,   38,   46,    1,    1,   46,   49,\n",
       "           42,  354,   60,    1,  131,   38,   50,  250,    1,   46,  301,    1,\n",
       "           73,   42,   53,  139,  163,  153,    1,  169,    1,  419,   42,    1,\n",
       "            1,  112,   42,  327,  165,   46,  301,    1,    1, 1165,  122,   68,\n",
       "          354,   57, 1423,   46,  107,   58,    1,    1,    1,   53,   33,    5,\n",
       "            1],\n",
       "        [   1,    2,    1,    7,   83,    1,    1,    1,  134,    1,  150,  151,\n",
       "           70,    1,    1,    1,   73,   68,  134,  162,  298,  139,  270,   15,\n",
       "            1,    1,  669,   38,  356,  107,    1,   73,  720,  165,  253,    1,\n",
       "           79,  852,    9,   98,   88,    5,  353,    1,   46,    1,  669,   38,\n",
       "           46,  168,  228,  381,  132,    1,   64,   46,  324,   38,    1,  107,\n",
       "          830,   42,   86,    1,    1,    1,   27,   70,    1,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(b_train, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "sents, lengths, labels = next(iter(train_loader))\n",
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic GRU Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(GRUModel,self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 14)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        print(x.shape)\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        pack = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "        out_pack, ht = self.gru(pack)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, optimizer, train_dl, valid_dl, epochs=10):\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, s, y in train_dl:\n",
    "            x = x.long()#.cuda()\n",
    "            y = y.float()#.cuda()\n",
    "            y_pred = model(x, s)\n",
    "            optimizer.zero_grad()\n",
    "            loss = nn.BCEWithLogitsLoss()(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        print(\"Epoch #%.f: train loss %.3f val loss %.3f and val accuracy %.3f\" % \n",
    "              (i+1,sum_loss/total, val_loss, val_acc))\n",
    "        \n",
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, s, y in valid_dl:\n",
    "        x = x.long()#.cuda()\n",
    "        y = y.float()#.cuda()\n",
    "        y_hat = model(x, s)\n",
    "        loss = nn.BCEWithLogitsLoss()(y_hat, y)\n",
    "        y_pred = y_hat > 0\n",
    "        correct += (y_pred.float() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50000\n",
    "train_dl = DataLoader(b_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_dl = DataLoader(b_valid, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15529\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "model = GRUModel(vocab_size, 50, 50)#.cuda()\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 520])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-fb2c930db3b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_epocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-111-bf05cbbc5de4>\u001b[0m in \u001b[0;36mtrain_epocs\u001b[0;34m(model, optimizer, train_dl, valid_dl, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0msum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_epocs(model, optimizer, train_dl, valid_dl, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
